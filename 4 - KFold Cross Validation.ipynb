{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6XaYG__Pf5Vy"
   },
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWyxk6Qxgfkd"
   },
   "source": [
    "K Fold cross validation is used to avoid overfitting. This technique is better then the train/test approach. In KFold Cross Validation approach we divide the data into K number of sets. One set is kept as the testing data and this test set is evaluated against all the remaining K-1 sets which are the training sets. At the end we take the avearage of all the error metrics provided by each training set and get the final error metric from the K Fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkAZW60zf5V5"
   },
   "outputs": [],
   "source": [
    "#import numpy for scientific calculations\n",
    "import numpy as np\n",
    "\n",
    "#split arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split,cross_val_score \n",
    "\n",
    "#embeds some small toy datasets\n",
    "from sklearn import datasets\n",
    "\n",
    "#set of supervised learning methods used for classification, regression and outliers detection\n",
    "from sklearn import svm\n",
    "\n",
    "#load and return the iris dataset (classification).\n",
    "iris = datasets.load_iris() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KU3nWs2Zf5WC"
   },
   "source": [
    "A single train/test split is made easy with the train_test_split function in the cross_validation library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QtkWkWbDf5WD",
    "outputId": "8f14fd90-847c-4540-c07d-0760b8ce0ffd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the iris data into train/test data sets with 40% reserved for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "#iris.data contains all the measurements of each flower\n",
    "#X.train 60% of data.\n",
    "#X_test 40% of data.\n",
    "#y_train and y_test contains species of each segment.\n",
    "\n",
    "#iris.target is the data which we want to predict, in this case it is the species of the flowers.\n",
    "#test_size=0.4-this splits the data with 40% data for testing and 60% training.\n",
    "# Build an SVC model for predicting iris classifications using training data\n",
    "clf = svm.SVC(kernel='linear', C=2).fit(X_train, y_train) \n",
    "#SVC model is built just using the training  species data and training , we fit the SVC model using the Linear Kernel. We call this model as CLF.\n",
    "# Now measure its performance with the test data\n",
    "clf.score(X_test, y_test) #here we call the score function of clf to measure its performance against test data set which contains iris measurements and the species.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhMMf82_ODMD"
   },
   "source": [
    "96% of the times the model predicts the species of an iris that is has never seen before just based on the measuremnet of the Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5gWontXf5WH"
   },
   "source": [
    "K-Fold cross validation is just as easy; let's use a K of 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3knYq2_Kf5WH",
    "outputId": "e4cacc43-0324-47a0-fd73-d98058eb18fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# We give cross_val_score a model, the entire data set and its \"real\" values, and the number of folds:\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10) #here we call cross_val_score and pass the model(clf),training data,testing data and divide the training data into 5 sets by using cv=5.\n",
    "\n",
    "# Print the accuracy for each fold:\n",
    "print(scores)\n",
    "\n",
    "# And the mean accuracy of all 5 folds:\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfGlrkIIRIOS"
   },
   "source": [
    "Here we get the list of error metric for each fold and then we take an avearge of error metric to get the overall error metric for 5 folds. By using 10 folds we improve the accuracy from 93% to 98%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKO4rV14f5WK"
   },
   "source": [
    "Our model is even better than we thought! Can we do better? Let's try a different kernel (poly):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4p112gdSvPQ"
   },
   "source": [
    "We will check whether there is a linear relation or polynomial relation between the species and the iris measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "OUz1Y7-xf5WK",
    "outputId": "e08e7ad7-9ef5-44d3-a1a3-76b80adc3d32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.9        0.93333333 1.        ]\n",
      "0.9666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=1).fit(X_train, y_train) #here we call the clf model by pass the kernel as polynomial.\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBU3w5NHf5WN"
   },
   "source": [
    "No! The more complex polynomial kernel produced lower accuracy than a simple linear kernel. The polynomial kernel is overfitting. But we couldn't have told that with a single train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ZQyInYRSf5WN",
    "outputId": "aa95d228-b9a2-43cd-b571-e536d2bd4c76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build an SVC model for predicting iris classifications using training data\n",
    "clf = svm.SVC(kernel='poly', C=2).fit(X_train, y_train)\n",
    "\n",
    "# Now measure its performance with the test data\n",
    "clf.score(X_test, y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hfjSjaIbf5WP"
   },
   "source": [
    "That's the same score we got with a single train/test split on the linear kernel."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KFoldCrossValidation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
